use core/types/sizeOf
use core/types/alignOf

// TODO: Move to <header> . <mem block> model vs separate struct
deftype Arena = {
  basePtr: Pointer,
  curAddr: uword,
  maxAddr: uword
}
ns Arena {
  let static mb: uword = 0x100000;
  let static gb: uword = 0x40000000;

  fn regionSizeBytes(self: Arena): uword {
    self.maxAddr - (self.basePtr as uword)
  }

  // Aligns 'base' to the next available value that is aligned with `align`
  // TODO(optimize): alignTo: Learn from Rust's 'align_offset' impl
  fn alignTo(baseAddress: uword, alignBytes: uword): uword {
    let mask = alignBytes - 1;
    let sum = baseAddress + mask;
    let aligned = Bitwise/bitAnd(sum, Bitwise/bitNot(mask));
    #if k1/DEBUG if aligned != baseAddress {
      println("Aligned \{baseAddress} to \{aligned}!")
    };
    aligned
  }

  fn new(initialMb: uword): Arena {
    let capacity = initialMb * mb;
    // We zero the memory because we don't make arenas that often
    // so it's worth it
    let basePtr = mem/allocZeroed(
      size = capacity, 
      align = 8
    );
    if basePtr.isNull() crash("calloc for Arena failed");
    {
      basePtr: basePtr,
      curAddr: basePtr as uword,
      maxAddr: basePtr as uword + capacity
    }
  }

  fn pushRaw(self: Arena*, size: uword, align: uword): Pointer {
    let dataStart = alignTo(self.curAddr, align);
    let newEnd = dataStart + size;
    if newEnd > self.maxAddr {
      crash("Arena is out of space to allocate \{size} bytes.")
    };

    self.curAddr* <- newEnd;
    dataStart as Pointer
  }

  fn push[T](self: Arena*, t: T): T* {
    let dataStart = self.pushRaw(sizeOf[T](), alignOf[T]());

    let ref: T* = dataStart as T*;
    ref <- t;
    ref
  }

  fn freeAll(self: Arena*): unit {
    let size = self.regionSizeBytes();
    println("[arena] Freeing \{size}");
    self.curAddr* <- (self.basePtr as uword);
  }
}
